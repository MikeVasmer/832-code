{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da7c4a-9bfe-45e3-9511-e1b86527d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c05db-efc3-42ae-97a6-d30bb7566c98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b16d9-0704-4fb5-b4d9-c430c0b46ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_distance(distributionA, distributionB, n):\n",
    "    \"\"\"\n",
    "    Calculate the statistical distance between two probability distributions on `n`-bit strings.\n",
    "    \n",
    "    Args:\n",
    "        distribution{A,B} (Dict[str, float]): keys are bitstrings and values are probabilities.\n",
    "    \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for bits in itertools.product([0, 1], repeat=n):\n",
    "        bit_string = ''.join(map(str, bits))\n",
    "        try:\n",
    "            total += abs(distributionA[bit_string] - distributionB[bit_string])\n",
    "        except KeyError:\n",
    "            total += distributionB[bit_string]\n",
    "    total = total / 2\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24d20c-1e23-43e3-857d-a3e0909f4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_bitstrings(bitstring1, bitstring2):\n",
    "    \"\"\"\n",
    "    Bitwise XOR of two bitstrings.\n",
    "    \n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    for i in range(len(bitstring1)):\n",
    "        current_xor = int(bitstring1[i]) ^ int(bitstring2[i])\n",
    "        result += str(current_xor)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b90d44-4276-41d7-bd87-8de98d152a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_to_probabilities(data_dict):\n",
    "    \"\"\"\n",
    "    Convert dictionary values from counts to probabilities.\n",
    "    \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for v in data_dict.values():\n",
    "        total += v\n",
    "    out = {k : v / total for k,v in data_dict.items()}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b21ed8-372e-475f-9d05-95ebabe74fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def little_to_big_endian(data_dict):\n",
    "    \"\"\"\n",
    "    Convert dictionary keys from little to big endian.\n",
    "    \n",
    "    \"\"\"\n",
    "    out_dict = {}\n",
    "    for k,v in data_dict.items():\n",
    "        out_dict[k[::-1]] = v\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24832fb8-84a4-470d-9e15-a80f8544cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_select(data_dict, valid_states):\n",
    "    \"\"\"\n",
    "    Remove dictionary items whose keys are not contained in `valid_states`.\n",
    "    \n",
    "    \"\"\"\n",
    "    post_data = {}\n",
    "    n = 0\n",
    "    n_post = 0\n",
    "    for k,v in data_dict.items():\n",
    "        n += v\n",
    "        if k in valid_states:\n",
    "            post_data[k] = v\n",
    "            n_post += v\n",
    "    return post_data, n_post/n  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27bd257-c562-4ac3-a634-5062573ddf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_states(seed, stabilizers):\n",
    "    \"\"\"\n",
    "    Return a bit-string representation of `stabilizers` applied to the state specified by `seed`.\n",
    "    \n",
    "    Args:\n",
    "        seed (str) : bit-string representation of the seed state.\n",
    "        stabilizers (List[str]) : list of stabilizers represented as bit-strings.\n",
    "    \n",
    "    \"\"\"\n",
    "    states = []\n",
    "    for combo in itertools.chain.from_iterable(itertools.combinations(stabilizers, r) for r in range(len(stabilizers)+1)):\n",
    "        if len(combo) == 0:\n",
    "            state = seed\n",
    "        elif len(combo) == 1:\n",
    "            state = xor_bitstrings(seed, combo[0])\n",
    "        elif len(combo) == 2:\n",
    "            state = xor_bitstrings(xor_bitstrings(seed, combo[0]), combo[1])\n",
    "        elif len(combo) == 3:\n",
    "            state = xor_bitstrings(xor_bitstrings(xor_bitstrings(seed, combo[0]), combo[1]), combo[2])\n",
    "        elif len(combo) == 4:\n",
    "            state = xor_bitstrings(xor_bitstrings(xor_bitstrings(xor_bitstrings(seed, combo[0]), combo[1]), combo[2]), combo[3])\n",
    "        states += [state]\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf01340-3c77-45be-abd5-f3f3db129007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physical_to_logical(physical, states, n):\n",
    "    \"\"\"\n",
    "    Map dictionary values from physical states to logical states.\n",
    "    \n",
    "    Args:\n",
    "        physical (Dict[str, numeric]): keys are physical states, values are counts/probabilities.\n",
    "        states (Dict[str, List[str]]): map from logical states to physical states\n",
    "        n (int) : number of bits in the logical state representation.\n",
    "        \n",
    "    \"\"\"\n",
    "    logical = {}\n",
    "    for bits in itertools.product([0, 1], repeat=n):\n",
    "        bit_string = ''.join(map(str, bits))\n",
    "        logical[bit_string] = 0\n",
    "    for k, v in physical.items():\n",
    "        for bit_string in logical.keys():\n",
    "            if k in states[bit_string]:\n",
    "                logical[bit_string] += v\n",
    "    return logical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ad0f2-483a-4b66-b817-d565907625f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df(data_dict):\n",
    "    \"\"\"\n",
    "    Convert dataframe into dict.\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for k, v in data_dict.items():\n",
    "        for i in range(int(v)):\n",
    "            df = pd.concat([df, pd.DataFrame([[k, 1]], columns=['result', 'counts'])], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e6a55-9ff6-45b3-84e0-bd55d2089109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dict(df):\n",
    "    \"\"\"\n",
    "    Convert dict into dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    keys = df['result'].unique()\n",
    "    for k in keys:\n",
    "        data_dict[k] = df[df['result'] == k].shape[0]\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04abbb-92e6-427b-baef-a4bb3d70dc86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expected distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33c54d-a19e-4cad-a68b-b1baa038b9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bits = ['0', '1']\n",
    "gates = [''.join(x) for x in itertools.product(bits, repeat=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dae61c-788b-443a-b853-f4279622a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_ghz_distribution = {\n",
    "    '000' : 0,\n",
    "    '001' : .25,\n",
    "    '010' : .25,\n",
    "    '011' : 0,\n",
    "    '100' : .25,\n",
    "    '101' : 0,\n",
    "    '110' : 0,\n",
    "    '111' : .25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f41bc00-4fc6-4157-b79e-c892ba3ce492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_ghz_distributions_z = {\n",
    "    g : {\n",
    "        '000' : .5,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : 0,\n",
    "        '100' : 0,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .5,\n",
    "    }\n",
    "    for g in gates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6d485-6409-4714-95ac-017dc0cda3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_ppp_distributions_z = {\n",
    "    g : {\n",
    "        '000' : .125,\n",
    "        '001' : .125,\n",
    "        '010' : .125,\n",
    "        '011' : .125,\n",
    "        '100' : .125,\n",
    "        '101' : .125,\n",
    "        '110' : .125,\n",
    "        '111' : .125,\n",
    "    }\n",
    "    for g in gates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3cf9a-4a28-467d-b92b-86b0cdf8f119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_ghz_distributions_x = {\n",
    "    '0000' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '1000' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '0100' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '0010' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '0001' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '1100' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '0110' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '1010' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '1001' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '0101' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '0011' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '1101' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '1011' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '0111' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '1110' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '1111' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1cf85-a0a8-40ef-894e-ca92b7f908d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_ppp_distributions_x = {\n",
    "    '0000' : {\n",
    "        '000' : 1,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : 0,\n",
    "        '100' : 0,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '0001' : {\n",
    "        '000' : .5625,\n",
    "        '001' : .0625,\n",
    "        '010' : .0625,\n",
    "        '011' : .0625,\n",
    "        '100' : .0625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .0625,\n",
    "    },\n",
    "    '0010' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : .25,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '0100' : {\n",
    "        '000' : .25,\n",
    "        '001' : .25,\n",
    "        '010' : 0,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : .25,\n",
    "        '110' : 0,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '1000' : {\n",
    "        '000' : .25,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : .25,\n",
    "        '100' : 0,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : 0,\n",
    "    },\n",
    "    '0011' : {\n",
    "        '000' : .5625,\n",
    "        '001' : .0625,\n",
    "        '010' : .0625,\n",
    "        '011' : .0625,\n",
    "        '100' : .0625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .0625,\n",
    "    },\n",
    "    '0101' : {\n",
    "        '000' : .5625,\n",
    "        '001' : .0625,\n",
    "        '010' : .0625,\n",
    "        '011' : .0625,\n",
    "        '100' : .0625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .0625,\n",
    "    },\n",
    "    '1001' : {\n",
    "        '000' : .5625,\n",
    "        '001' : .0625,\n",
    "        '010' : .0625,\n",
    "        '011' : .0625,\n",
    "        '100' : .0625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .0625,\n",
    "    },\n",
    "    '1100' : {\n",
    "        '000' : .25,\n",
    "        '001' : .25,\n",
    "        '010' : 0,\n",
    "        '011' : 0,\n",
    "        '100' : 0,\n",
    "        '101' : 0,\n",
    "        '110' : .25,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '1010' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : 0,\n",
    "        '101' : .25,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '0110' : {\n",
    "        '000' : .25,\n",
    "        '001' : 0,\n",
    "        '010' : 0,\n",
    "        '011' : .25,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '1110' : {\n",
    "        '000' : 0,\n",
    "        '001' : .25,\n",
    "        '010' : .25,\n",
    "        '011' : 0,\n",
    "        '100' : .25,\n",
    "        '101' : 0,\n",
    "        '110' : 0,\n",
    "        '111' : .25,\n",
    "    },\n",
    "    '1011' : {\n",
    "        '000' : .0625,\n",
    "        '001' : .0625,\n",
    "        '010' : .5625,\n",
    "        '011' : .0625,\n",
    "        '100' : .0625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .0625,\n",
    "    },\n",
    "    '0111' : {\n",
    "        '000' : .0625,\n",
    "        '001' : .0625,\n",
    "        '010' : .0625,\n",
    "        '011' : .0625,\n",
    "        '100' : .5625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .0625,\n",
    "    },\n",
    "    '1101' : {\n",
    "        '000' : .0625,\n",
    "        '001' : .5625,\n",
    "        '010' : .0625,\n",
    "        '011' : .0625,\n",
    "        '100' : .0625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .0625,\n",
    "    },\n",
    "    '1111' : {\n",
    "        '000' : .0625,\n",
    "        '001' : .0625,\n",
    "        '010' : .0625,\n",
    "        '011' : .0625,\n",
    "        '100' : .0625,\n",
    "        '101' : .0625,\n",
    "        '110' : .0625,\n",
    "        '111' : .5625,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcc59d-fe1f-4515-a07a-a10fcc1922c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_distributions_dict = {\n",
    "    '+++' : {\n",
    "        'x' : expected_ppp_distributions_x,\n",
    "        'z' : expected_ppp_distributions_z\n",
    "    },\n",
    "    'ghz' : {\n",
    "        'x' : expected_ghz_distributions_x,\n",
    "        'z' : expected_ghz_distributions_z\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec0f8e-2d87-47ea-a730-cc0370476751",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $[\\![8,3,2]\\!]$ states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff389fc1-896b-496e-8763-074e735e16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439ce0f-03fe-459d-bbff-57493fc01a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_states_832_x = [''.join(x) for x in itertools.product(bits, repeat=n) if x.count('1') % 2 == 0]\n",
    "stabilizers_z = ['11110000', '00001111', '10101010', '11001100']\n",
    "states_map_832_x = {\n",
    "    '000' : logical_states('00000000', stabilizers_z),\n",
    "    '001' : logical_states('10001000', stabilizers_z),\n",
    "    '010' : logical_states('10100000', stabilizers_z),\n",
    "    '011' : logical_states('00101000', stabilizers_z),\n",
    "    '100' : logical_states('11000000', stabilizers_z),\n",
    "    '101' : logical_states('01001000', stabilizers_z),\n",
    "    '110' : logical_states('01100000', stabilizers_z),\n",
    "    '111' : logical_states('11101000', stabilizers_z),\n",
    "}\n",
    "sorted(valid_states_832_x) == sorted([item for sublist in states_map_832_x.values() for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815b562-41e1-4483-a610-5da93e77c5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stabilizers_x = ['11111111']\n",
    "states_map_832_z = {\n",
    "    '000' : logical_states('00000000', stabilizers_x),\n",
    "    '001' : logical_states('10101010', stabilizers_x),\n",
    "    '010' : logical_states('11001100', stabilizers_x),\n",
    "    '011' : logical_states('01100110', stabilizers_x),\n",
    "    '100' : logical_states('11110000', stabilizers_x),\n",
    "    '101' : logical_states('01011010', stabilizers_x),\n",
    "    '110' : logical_states('00111100', stabilizers_x),\n",
    "    '111' : logical_states('10010110', stabilizers_x),\n",
    "}\n",
    "valid_states_832_z = [item for sublist in states_map_832_z.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5b981-badf-4650-85e6-943135a9c8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "states_map_832_dict = {'x' : states_map_832_x, 'z' : states_map_832_z}\n",
    "valid_states_832_dict = {'x' : valid_states_832_x, 'z' : valid_states_832_z}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89870553-fe42-4ad4-9bac-06545f1abe63",
   "metadata": {},
   "source": [
    "## Build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7522e95-eb4a-44e6-8e35-36f494dac38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {'qpu' : 'ionq-11q', 'date' : '2023-08-17'},\n",
    "    {'qpu' : 'ionq-11q', 'date' : '2023-07-26'},\n",
    "    {'qpu' : 'ibmq_mumbai', 'date' : '2023-04-14'},\n",
    "]\n",
    "resamplings = 100\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "for experiment in experiments:\n",
    "    with open(f'data-{experiment[\"qpu\"]}-{experiment[\"date\"]}.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for sp in ['+++', 'ghz']:\n",
    "        for meas in ['x', 'z']:\n",
    "            states_map_832 = states_map_832_dict[meas]\n",
    "            valid_states_832 = valid_states_832_dict[meas]\n",
    "            statistical_distances = []\n",
    "            errs = []\n",
    "            post_selection_rates = []\n",
    "            encodings = []\n",
    "            for g in tqdm(gates):\n",
    "                try:\n",
    "                    distances = []\n",
    "                    expected_distributions = expected_distributions_dict[sp][meas]\n",
    "                    # The df conversion is slow so we do it outside the loop\n",
    "                    df = dict_to_df(data[f'bare_prep={sp}_gate={g}_readout={meas}'])\n",
    "                    # print(df)\n",
    "                    for i in range(resamplings):\n",
    "                        bare_distribution = counts_to_probabilities(df_to_dict(df.sample(frac=1, replace=True)))\n",
    "                        distances += [statistical_distance(bare_distribution, expected_distributions[g], 3)]\n",
    "                    statistical_distances += [np.mean(distances)]\n",
    "                    errs += [np.std(distances)]\n",
    "                    post_selection_rates += [1]\n",
    "                    if g == '0000':\n",
    "                        encodings += ['bare']\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    distances = []\n",
    "                    post_rates = []\n",
    "                    df = dict_to_df(little_to_big_endian(data[f'enc_prep={sp}_gate={g}_readout={meas}']))\n",
    "                    for i in range(resamplings):\n",
    "                        post_data, post_rate = post_select(df_to_dict(df.sample(frac=1, replace=True)), valid_states_832)\n",
    "                        enc_distribution = counts_to_probabilities(physical_to_logical(post_data, states_map_832, 3))\n",
    "                        distances += [statistical_distance(enc_distribution, expected_distributions[g], 3)]\n",
    "                        post_rates += [post_rate]\n",
    "                    statistical_distances += [np.mean(distances)]\n",
    "                    errs += [np.std(distances)]\n",
    "                    post_selection_rates += [np.mean(post_rates)]\n",
    "                    if g == '0000':\n",
    "                        encodings += ['[[8,3,2]]']\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "                try:\n",
    "                    distances = []\n",
    "                    post_rates = []\n",
    "                    df = dict_to_df(little_to_big_endian(data[f'encf_prep={sp}_gate={g}_readout={meas}']))\n",
    "                    valid_states_832_flag = []\n",
    "                    for state in valid_states_832:\n",
    "                        flag_state = state + \"000\"\n",
    "                        valid_states_832_flag += [flag_state]\n",
    "                    for i in range(resamplings):\n",
    "                        post_data, post_rate = post_select(df_to_dict(df.sample(frac=1, replace=True)), valid_states_832_flag)\n",
    "                        new_post_data = {}\n",
    "                        for k in post_data.keys():\n",
    "                            new_post_data[k[0:8]] = post_data[k]\n",
    "                        enc_distribution = counts_to_probabilities(physical_to_logical(new_post_data, states_map_832, 3))\n",
    "                        distances += [statistical_distance(enc_distribution, expected_distributions[g], 3)]\n",
    "                        post_rates += [post_rate]\n",
    "                    statistical_distances += [np.mean(distances)]\n",
    "                    errs += [np.std(distances)]\n",
    "                    post_selection_rates += [np.mean(post_rates)]\n",
    "                    if g == '0000':\n",
    "                        encodings += ['[[8,3,2]] flag']\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            \n",
    "            if len(errs) > 0:\n",
    "                df = pd.DataFrame.from_dict({\n",
    "                    'date' : [experiment['date']] * len(errs),\n",
    "                    'qpu' : [experiment['qpu']] * len(errs),\n",
    "                    'state-prep' : [sp] * len(errs),\n",
    "                    'readout' : [meas] * len(errs),\n",
    "                    'encoding' : encodings * (len(errs) // len(encodings)),\n",
    "                    'gate' : [item[::-1] for sublist in [[g] * (len(errs) // len(gates)) for g in gates] for item in sublist],\n",
    "                    'distance': statistical_distances,\n",
    "                    'error': errs,\n",
    "                    'post-select': post_selection_rates\n",
    "                })\n",
    "                df = df.sort_values(by=['gate', 'encoding'])\n",
    "                df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "            \n",
    "df_all.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8de455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
